{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "load_dotenv(dotenv_path='../.envrc')\n",
    "embedding_function = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>orig</th>\n",
       "      <th>pdf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://papers.nips.cc/paper/4824-imagenet-cla...</td>\n",
       "      <td>https://papers.nips.cc/paper/4824-imagenet-cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://arxiv.org/abs/1406.2661</td>\n",
       "      <td>https://arxiv.org/pdf/1406.2661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://arxiv.org/abs/1409.1556</td>\n",
       "      <td>https://arxiv.org/pdf/1409.1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://arxiv.org/abs/1512.03385</td>\n",
       "      <td>https://arxiv.org/pdf/1512.03385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://arxiv.org/abs/1409.4842</td>\n",
       "      <td>https://arxiv.org/pdf/1409.4842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>https://arxiv.org/pdf/1410.5401.pdf</td>\n",
       "      <td>https://arxiv.org/pdf/1410.5401.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>https://arxiv.org/pdf/1512.02595.pdf</td>\n",
       "      <td>https://arxiv.org/pdf/1512.02595.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>101</td>\n",
       "      <td>https://arxiv.org/pdf/2001.08361.pdf</td>\n",
       "      <td>https://arxiv.org/pdf/2001.08361.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>https://arxiv.org/pdf/math/0406077.pdf</td>\n",
       "      <td>https://arxiv.org/pdf/math/0406077.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>103</td>\n",
       "      <td>https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf</td>\n",
       "      <td>https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                               orig  \\\n",
       "0             0  https://papers.nips.cc/paper/4824-imagenet-cla...   \n",
       "1             1                    https://arxiv.org/abs/1406.2661   \n",
       "2             2                    https://arxiv.org/abs/1409.1556   \n",
       "3             3                   https://arxiv.org/abs/1512.03385   \n",
       "4             4                    https://arxiv.org/abs/1409.4842   \n",
       "..          ...                                                ...   \n",
       "99           99                https://arxiv.org/pdf/1410.5401.pdf   \n",
       "100         100               https://arxiv.org/pdf/1512.02595.pdf   \n",
       "101         101               https://arxiv.org/pdf/2001.08361.pdf   \n",
       "102         102             https://arxiv.org/pdf/math/0406077.pdf   \n",
       "103         103  https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf   \n",
       "\n",
       "                                                   pdf  \n",
       "0    https://papers.nips.cc/paper/4824-imagenet-cla...  \n",
       "1                      https://arxiv.org/pdf/1406.2661  \n",
       "2                      https://arxiv.org/pdf/1409.1556  \n",
       "3                     https://arxiv.org/pdf/1512.03385  \n",
       "4                      https://arxiv.org/pdf/1409.4842  \n",
       "..                                                 ...  \n",
       "99                 https://arxiv.org/pdf/1410.5401.pdf  \n",
       "100               https://arxiv.org/pdf/1512.02595.pdf  \n",
       "101               https://arxiv.org/pdf/2001.08361.pdf  \n",
       "102             https://arxiv.org/pdf/math/0406077.pdf  \n",
       "103  https://www.lirmm.fr/~ashen/kolmbook-eng-scan.pdf  \n",
       "\n",
       "[104 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('db_links.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'\\x89PNG\\r'\n",
      "EOF marker not found\n",
      "EOF marker not found\n",
      "EOF marker not found\n",
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 34 65536 (offset 0)\n",
      "Ignoring wrong pointing object 92 65536 (offset 0)\n",
      "Ignoring wrong pointing object 145 65536 (offset 0)\n",
      "Ignoring wrong pointing object 206 65536 (offset 0)\n",
      "Ignoring wrong pointing object 274 65536 (offset 0)\n",
      "Ignoring wrong pointing object 330 65536 (offset 0)\n",
      "Ignoring wrong pointing object 372 65536 (offset 0)\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "for i in range(0, len(df)):\n",
    "    try:\n",
    "        loader = PyPDFLoader(df.loc[i, 'pdf'])\n",
    "        pages.extend(loader.load_and_split())\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2500,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for doc in pages:\n",
    "    temp = text_splitter.create_documents(doc.page_content)\n",
    "    for t in temp:\n",
    "        t.metadata['source'] = doc.metadata['source']\n",
    "        t.metadata['page'] = doc.metadata['page']\n",
    "    docs.extend(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(pages, embedding_function, persist_directory=\"paper_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma(persist_directory=\"paper_info\", embedding_function=embedding_function)\n",
    "retriever = db.as_retriever(search_kwargs={'k': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a helpful deep learning mentor. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: \n",
    "    {question}\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = format_docs(search_results)\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def search(query):\n",
    "\n",
    "    results = retriever.invoke(query)\n",
    "    return results\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main idea of the attention mechanism is to dynamically focus on different parts of the input data when producing the output. This approach assigns weights to different input values based on a compatibility function between a query and corresponding keys, allowing the model to emphasize relevant information and ignore less pertinent information at each step of the output generation.\\n\\nFor example, in image captioning, the attention mechanism allows the model to \"attend\" to various regions of an image while generating the corresponding textual description. Similarly, in natural language processing tasks like translation, it helps the model to focus on relevant words in the source sentence when generating each word in the target sentence. Scaled Dot-Product Attention and Multi-Head Attention are specific implementations that enhance the capability to attend to different parts of the input more effectively and in parallel, respectively. The former scales the dot product by the dimension of the keys to prevent large gradients in the softmax function, while the latter projects keys, values, and queries multiple times with different learned projections, performing the attention function in parallel.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What is the main idea of attention mechanism?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
